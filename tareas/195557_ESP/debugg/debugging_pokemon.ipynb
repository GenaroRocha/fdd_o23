{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import StringIO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagina que eres un investigador en el mundo de Pokémon y has recibido una base de datos con información desactualizada y desordenada sobre avistamientos de Pokémon. Tu misión es limpiar y actualizar esta base de datos para que pueda ser utilizada en un estudio sobre la población de Pokémon en la región."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datos Iniciales\n",
    "\n",
    "Los datos iniciales contienen las siguientes columnas:\n",
    "\n",
    "    SightingDate: Fecha del avistamiento.\n",
    "    TrainerID: Identificación del entrenador que reportó el avistamiento.\n",
    "    PokemonName: Nombre del Pokémon avistado.\n",
    "    CP: Puntos de combate del Pokémon reportado.\n",
    "    HP: Puntos de salud del Pokémon reportado.\n",
    "    Type: Tipo del Pokémon.\n",
    "    Weather: Clima durante el avistamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Carga de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_datos = 'pokemon.csv'\n",
    "# TODO completa el codigo para cargar los datos\n",
    "# df = pd.read_csv(path_datos)\n",
    "df = pd.read_csv(path_datos, encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Normalizacion de Zonas Horarias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normaliza la columna `'SightingTimeUTC'` a la zona horaria UTC y convierte `'SightingDate'` al mismo formato de tiempo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   2023-11-08 14:00:00+00:00\n",
      "1   2023-07-12 08:30:00+00:00\n",
      "2   2023-02-23 13:15:00+00:00\n",
      "3   2023-04-30 10:45:00+00:00\n",
      "4   2023-08-15 06:00:00+00:00\n",
      "Name: SightingDate, dtype: datetime64[ns, UTC]\n"
     ]
    }
   ],
   "source": [
    "# Intentar convertir 'SightingDate' a fecha y hora con zona horaria UTC\n",
    "df['SightingDate'] = pd.to_datetime(df['SightingDate'], errors='coerce', utc=True)\n",
    "\n",
    "# Verificar la conversión\n",
    "print(df['SightingDate'].head())\n",
    "df['SightingTimeUTC'] = pd.to_datetime(df['SightingTimeUTC'], errors='coerce', utc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compara si la fecha de la columna `'SightingDate'` coincide con la fecha en `'SightingTimeUTC'` una vez normalizada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SightingDate       datetime64[ns, UTC]\n",
      "SightingTimeUTC    datetime64[ns, UTC]\n",
      "TrainerID                       object\n",
      "PokémonName                     object\n",
      "CP                              object\n",
      "HP                               int64\n",
      "Type                            object\n",
      "Weather                         object\n",
      "DateMatch                         bool\n",
      "dtype: object\n",
      "Una de las columnas no es de tipo fecha y hora.\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)\n",
    "# Si ambos son de tipo fecha y hora, realizar la comparación\n",
    "if df['SightingDate'].dtype == '<M8[ns]' and df['SightingTimeUTC'].dtype == '<M8[ns]':\n",
    "    df['DateMatch'] = df['SightingDate'].dt.date == df['SightingTimeUTC'].dt.date\n",
    "else:\n",
    "    print(\"Una de las columnas no es de tipo fecha y hora.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               SightingDate           SightingTimeUTC  DateMatch\n",
      "0 2023-11-08 14:00:00+00:00 2023-11-08 14:00:00+00:00       True\n",
      "1 2023-07-12 08:30:00+00:00 2023-07-12 08:30:00+00:00       True\n",
      "2 2023-02-23 13:15:00+00:00 2023-02-23 13:15:00+00:00       True\n",
      "3 2023-04-30 10:45:00+00:00 2023-04-30 10:45:00+00:00       True\n",
      "4 2023-08-15 06:00:00+00:00                       NaT      False\n"
     ]
    }
   ],
   "source": [
    "# Comprobar si las fechas (sin contar la hora) coinciden\n",
    "df['DateMatch'] = df['SightingDate'].dt.date == df['SightingTimeUTC'].dt.date\n",
    "\n",
    "# Verificar los resultados\n",
    "print(df[['SightingDate', 'SightingTimeUTC', 'DateMatch']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajusta `'SightingTimeUTC'` a la zona horaria local de cada entrenador y crea una columna `'SightingTimeLocal'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               SightingDate           SightingTimeUTC  \\\n",
      "0 2023-11-08 14:00:00+00:00 2023-11-08 14:00:00+00:00   \n",
      "1 2023-07-12 08:30:00+00:00 2023-07-12 08:30:00+00:00   \n",
      "2 2023-02-23 13:15:00+00:00 2023-02-23 13:15:00+00:00   \n",
      "3 2023-04-30 10:45:00+00:00 2023-04-30 10:45:00+00:00   \n",
      "4 2023-08-15 06:00:00+00:00                       NaT   \n",
      "\n",
      "          SightingTimeLocal  \n",
      "0 2023-11-08 14:00:00+00:00  \n",
      "1 2023-07-12 08:30:00+00:00  \n",
      "2 2023-02-23 13:15:00+00:00  \n",
      "3 2023-04-30 10:45:00+00:00  \n",
      "4                       NaT  \n"
     ]
    }
   ],
   "source": [
    "# Extraer la zona horaria de 'SightingDate' y convertir 'SightingTimeUTC'\n",
    "df['SightingTimeLocal'] = df.apply(\n",
    "    lambda row: row['SightingTimeUTC'].tz_convert(row['SightingDate'].tz) if pd.notnull(row['SightingTimeUTC']) else pd.NaT, \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Verificar los resultados\n",
    "print(df[['SightingDate', 'SightingTimeUTC', 'SightingTimeLocal']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcula el tiempo transcurrido desde el momento del avistamiento hasta `'ahora'` (tu hora local) y crea una columna `'TimeSinceSighting'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               SightingDate        TimeSinceSighting\n",
      "0 2023-11-08 14:00:00+00:00   0 days 10:12:03.154291\n",
      "1 2023-07-12 08:30:00+00:00 119 days 15:42:03.154291\n",
      "2 2023-02-23 13:15:00+00:00 258 days 10:57:03.154291\n",
      "3 2023-04-30 10:45:00+00:00 192 days 13:27:03.154291\n",
      "4 2023-08-15 06:00:00+00:00  85 days 18:12:03.154291\n"
     ]
    }
   ],
   "source": [
    "# Obtener la hora actual en UTC\n",
    "now_utc = pd.Timestamp.now(tz='UTC')\n",
    "\n",
    "# Calcular el tiempo transcurrido desde el avistamiento hasta ahora\n",
    "df['TimeSinceSighting'] = now_utc - df['SightingDate']\n",
    "\n",
    "# Verificar los resultados\n",
    "print(df[['SightingDate', 'TimeSinceSighting']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Limpeiza de IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llena los valores faltantes en `'TrainerID'` con el ID `'UNKNOWN'`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores faltantes antes de fillna: 0\n",
      "Valores faltantes después de fillna: 0\n",
      "  TrainerID\n",
      "0     TR123\n",
      "1     TR456\n",
      "2     TR789\n",
      "3     TR101\n",
      "4     TR102\n"
     ]
    }
   ],
   "source": [
    "# Verificar si hay valores faltantes en 'TrainerID' antes de aplicar fillna\n",
    "print(\"Valores faltantes antes de fillna:\", df['TrainerID'].isna().sum())\n",
    "\n",
    "# Llenar los valores faltantes en 'TrainerID' con 'UNKNOWN'\n",
    "df['TrainerID'] = df['TrainerID'].fillna('UNKNOWN')\n",
    "\n",
    "# Verificar si hay valores faltantes después de aplicar fillna\n",
    "print(\"Valores faltantes después de fillna:\", df['TrainerID'].isna().sum())\n",
    "\n",
    "# Verificar los resultados\n",
    "print(df[['TrainerID']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Corrección de Nombres de Pokémon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asegúrate de que los nombres de Pokémon estén capitalizados correctamente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      Pikachu\n",
      "1        Eevee\n",
      "2     Magicarp\n",
      "3       Gengar\n",
      "4    Bulbasaur\n",
      "Name: PokémonName, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Capitalizar correctamente los nombres de Pokémon\n",
    "df['PokémonName'] = df['PokémonName'].str.title()\n",
    "\n",
    "# Verificar los resultados\n",
    "print(df['PokémonName'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conversión de 'CP' y 'HP' a Numéricos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convierte `'CP'` y `'HP'` a valores numéricos, manejando los `'MISSING'` y comas como separadores de miles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       CP  HP\n",
      "0   500.0  35\n",
      "1     NaN  55\n",
      "2  1000.0  10\n",
      "3   800.0  45\n",
      "4   750.0  50\n"
     ]
    }
   ],
   "source": [
    "# Convertir 'CP' a numérico, reemplazando 'MISSING' por NaN y manejando las comas\n",
    "df['CP'] = pd.to_numeric(df['CP'].str.replace(',', ''), errors='coerce')\n",
    "\n",
    "# Convertir 'HP' a numérico, reemplazando 'MISSING' por NaN\n",
    "df['HP'] = pd.to_numeric(df['HP'], errors='coerce')\n",
    "\n",
    "# Verificar los resultados\n",
    "print(df[['CP', 'HP']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Estandarización de 'Type'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide la columna `'Type'` en `'PrimaryType'` y `'SecondaryType'` cuando hay dos tipos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Type PrimaryType SecondaryType\n",
      "0      Electric    Electric          None\n",
      "1        Normal      Normal          None\n",
      "2         Water       Water          None\n",
      "3         Ghost       Ghost          None\n",
      "4  Grass/Poison       Grass        Poison\n"
     ]
    }
   ],
   "source": [
    "# Dividir la columna 'Type' en 'PrimaryType' y 'SecondaryType'\n",
    "df[['PrimaryType', 'SecondaryType']] = df['Type'].str.split('/', n=1, expand=True)\n",
    "\n",
    "# Verificar los resultados\n",
    "print(df[['Type', 'PrimaryType', 'SecondaryType']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Corrección del Clima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estándariza la columna `'Weather'` para que todos los valores sean mayúsculas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Weather\n",
      "0          CLEAR\n",
      "1         CLOUDY\n",
      "2           RAIN\n",
      "3  PARTLY_CLOUDY\n",
      "4          SUNNY\n"
     ]
    }
   ],
   "source": [
    "# Convertir todos los valores de la columna 'Weather' a mayúsculas\n",
    "df['Weather'] = df['Weather'].str.upper()\n",
    "\n",
    "# Verificar los resultados\n",
    "print(df[['Weather']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Analisis de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrupaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agrupa el DataFrame por `'Type'` y calcula la suma de `'CP'` para cada grupo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type\n",
      "Electric         500.0\n",
      "Ghost            800.0\n",
      "Grass/Poison     750.0\n",
      "Normal             0.0\n",
      "Water           1000.0\n",
      "Name: CP, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Agrupar por 'Type' y calcular la suma de 'CP' para cada grupo\n",
    "sum_cp_by_type = df.groupby('Type')['CP'].sum()\n",
    "\n",
    "# Ver los resultados\n",
    "print(sum_cp_by_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de la suma, agrega una columna que calcule la media de `'HP'` por cada `'Type'`, pero solo para aquellos Pokémon cuyo `'CP'` sea mayor que el promedio de `'CP'` de todo el DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type\n",
      "Ghost    45.0\n",
      "Water    10.0\n",
      "Name: HP, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Tu codigo aqui\n",
    "# Calcular el promedio de 'CP' de todo el DataFrame\n",
    "average_cp = df['CP'].mean()\n",
    "\n",
    "# Filtrar para incluir solo Pokémon cuyo 'CP' sea mayor que el promedio\n",
    "filtered_df = df[df['CP'] > average_cp]\n",
    "\n",
    "# Agrupar por 'Type' y calcular la media de 'HP' para cada grupo\n",
    "mean_hp_by_type = filtered_df.groupby('Type')['HP'].mean()\n",
    "\n",
    "# Ver los resultados\n",
    "print(mean_hp_by_type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
